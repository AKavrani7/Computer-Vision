{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Include Libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuration of Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convolutional Layer 1.\n",
    "filter_size1 = 5          # Convolution filters are 5 x 5 pixels.\n",
    "num_filters1 = 16         # There are 16 of these filters.\n",
    "\n",
    "# Convolutional Layer 2.\n",
    "filter_size2 = 5          # Convolution filters are 5 x 5 pixels.\n",
    "num_filters2 = 36         # There are 36 of these filters.\n",
    "\n",
    "# Fully-connected layer.\n",
    "fc_size = 128             # Number of neurons in fully-connected layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1 Load Data  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load DataSet\n",
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n",
      "\n",
      "Total 70,000 Images\n",
      "Size of:\n",
      "- Training-set:\t\t55000\n",
      "- Validation-set:\t10000\n",
      "- Test-set:\t\t5000\n",
      "\n",
      "Properties of image\n",
      "Image_Size:  28\n",
      "img_size_flat:  784\n",
      "img_shape:  (28, 28)\n",
      "num_classes:  10\n",
      "num_channels:  1\n"
     ]
    }
   ],
   "source": [
    "print(\"Load DataSet\")\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "data = input_data.read_data_sets(\"/tmp/data/\", one_hot = True)\n",
    "print()\n",
    "\n",
    "print(\"Total 70,000 Images\")\n",
    "print(\"Size of:\")\n",
    "print(\"- Training-set:\\t\\t{}\".format(len(data.train.labels)))\n",
    "print(\"- Validation-set:\\t{}\".format(len(data.test.labels)))\n",
    "print(\"- Test-set:\\t\\t{}\".format(len(data.validation.labels)))\n",
    "print()\n",
    "\n",
    "print(\"Properties of image\")\n",
    "# The number of pixels in each dimension of an image.\n",
    "img_size = 28\n",
    "print(\"Image_Size: \",img_size)\n",
    "\n",
    "# The images are stored in one-dimensional arrays of this length.\n",
    "img_size_flat = 28*28\n",
    "print(\"img_size_flat: \",img_size_flat)\n",
    "\n",
    "# Tuple with height and width of images used to reshape arrays.\n",
    "img_shape = (28,28)\n",
    "print(\"img_shape: \",img_shape)\n",
    "\n",
    "# Number of classes, one class for each of 10 digits.\n",
    "num_classes = 10\n",
    "print(\"num_classes: \",num_classes)\n",
    "\n",
    "# Number of colour channels for the images: 1 channel for gray-scale.\n",
    "num_channels = 1\n",
    "print(\"num_channels: \",num_channels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2  Tensorflow Setup Part A Tensorflow Graph\n",
    "\n",
    "A TensorFlow graph consists of the following parts which will be detailed below: \n",
    "\n",
    "* Placeholder variables used for inputting data to the graph.\n",
    "* Variables that are going to be optimized so as to make the convolutional network perform better.\n",
    "* The mathematical formulas for the convolutional network.\n",
    "* A cost measure that can be used to guide the optimization of the variables.\n",
    "* An optimization method which updates the variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Helper Functions\n",
    "\n",
    "#1. Construct Variables Wg and Bias\n",
    "def new_weights(shape):\n",
    "    return tf.Variable(tf.truncated_normal(shape, stddev=0.05))\n",
    "def new_biases(length):\n",
    "    return tf.Variable(tf.constant(0.05, shape=[length]))\n",
    "\n",
    "#2. Create a Convolutional Layer\n",
    "def new_convo_layer(input, num_input_channels, filter_size, num_filters, use_pooling = True):\n",
    "    \n",
    "    #filter_size, Width and height of each filter.\n",
    "    # This format is determined by the TensorFlow API.\n",
    "    shape = [filter_size, filter_size, num_input_channels, num_filters] \n",
    "    weights = new_weights(shape=shape)\n",
    "    biases = new_biases(length=num_filters)\n",
    "    \n",
    "    #Layer\n",
    "    # Strides = [1, 2, 2, 1] would mean that the filter\n",
    "    # is moved 2 pixels across the x- and y-axis of the image.\n",
    "    # The padding is set to 'SAME' which means the input image \n",
    "    # is padded with zeroes so the size of the output is the same.\n",
    "    layer = tf.nn.conv2d(input=input, filter=weights, strides=[1, 1, 1, 1], padding='SAME') \n",
    "    layer = layer + biases\n",
    "    \n",
    "    #We use Pooling to down-sample the image resolution \n",
    "    if use_pooling:\n",
    "        # This is 2x2 max-pooling, which means that we\n",
    "        # consider 2x2 windows and select the largest value\n",
    "        # in each window. Then we move 2 pixels to the next window.\n",
    "        layer = tf.nn.max_pool(value=layer, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "    \n",
    "    # Rectified Linear Unit (ReLU).\n",
    "    layer = tf.nn.relu(layer)\n",
    "    return layer, weights\n",
    "\n",
    "#3. Flattening a layer\n",
    "def flatten_layer(layer):\n",
    "    # Get the shape of the input layer.\n",
    "    # layer_shape == [num_images, img_height, img_width, num_channels]\n",
    "    layer_shape = layer.get_shape()\n",
    "    \n",
    "    # The number of features is: img_height * img_width * num_channels\n",
    "    num_features = layer_shape[1:4].num_elements()\n",
    "    \n",
    "    # Reshape the layer to [num_images, num_features].\n",
    "    # Note that we just set the size of the second dimension\n",
    "    # to num_features and the size of the first dimension to -1\n",
    "    # which means the size in that dimension is calculated\n",
    "    # so the total size of the tensor is unchanged from the reshaping.\n",
    "    layer_flat = tf.reshape(layer, [-1, num_features])\n",
    "\n",
    "    # The shape of the flattened layer is now:\n",
    "    # [num_images, img_height * img_width * num_channels]\n",
    "\n",
    "    # Return both the flattened layer and the number of features.\n",
    "    return layer_flat, num_features\n",
    "    \n",
    "\n",
    "#4. New FUlly Connected Layer\n",
    "def new_fc_layer(input, num_inputs, num_outputs, use_relu=True): # Use Rectified Linear Unit (ReLU)?\n",
    "\n",
    "    # Create new weights and biases.\n",
    "    weights = new_weights(shape=[num_inputs, num_outputs])\n",
    "    biases = new_biases(length=num_outputs)\n",
    "\n",
    "    # Calculate the layer as the matrix multiplication of\n",
    "    # the input and weights, and then add the bias-values.\n",
    "    layer = tf.matmul(input, weights) + biases\n",
    "\n",
    "    # Use ReLU?\n",
    "    if use_relu:\n",
    "        layer = tf.nn.relu(layer)\n",
    "\n",
    "    return layer\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A.1 Placeholder\n",
    "\n",
    "Placeholder variables serve as the input to the TensorFlow computational graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, shape=[None, img_size_flat], name='x')\n",
    "#The convolutional layers expect x to be encoded as a 4-dim tensor\n",
    "# -1: Num_Images, img_size == img_H == Img_W, Num_Channels\n",
    "x_image = tf.reshape(x, [-1, img_size, img_size, num_channels])\n",
    "\n",
    "y_true = tf.placeholder(tf.float32, shape=[None, num_classes], name='y_true')\n",
    "\n",
    "y_true_cls = tf.argmax(y_true, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A.2 CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer_Convo_1\n",
      "Tensor(\"Relu_3:0\", shape=(?, 14, 14, 16), dtype=float32)\n",
      "Layer_Convo_2\n",
      "Tensor(\"Relu_4:0\", shape=(?, 7, 7, 36), dtype=float32)\n",
      "layer_flat\n",
      "Tensor(\"Reshape_2:0\", shape=(?, 1764), dtype=float32)\n",
      "num_features\n",
      "1764\n",
      "layer_fc1\n",
      "Tensor(\"Relu_5:0\", shape=(?, 128), dtype=float32)\n",
      "layer_fc2\n",
      "Tensor(\"add_7:0\", shape=(?, 10), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "#1. Convolutional Layer 1\n",
    "layer_conv1, weights_conv1 = new_convo_layer(input=x_image, \n",
    "                                            num_input_channels=num_channels,\n",
    "                                            filter_size=filter_size1,\n",
    "                                            num_filters=num_filters1,\n",
    "                                            use_pooling=True)\n",
    "print(\"Layer_Convo_1\")\n",
    "print(layer_conv1)\n",
    "\n",
    "#2. Convolutional Layer 2\n",
    "layer_conv2, weights_conv2 = new_convo_layer(input=layer_conv1, \n",
    "                                            num_input_channels=num_filters1,\n",
    "                                            filter_size=filter_size2,\n",
    "                                            num_filters=num_filters2,\n",
    "                                            use_pooling=True)\n",
    "print(\"Layer_Convo_2\")\n",
    "print(layer_conv2)\n",
    "\n",
    "#3. Flatten Layer\n",
    "layer_flat, num_features = flatten_layer(layer_conv2)\n",
    "\n",
    "print(\"layer_flat\")\n",
    "print(layer_flat)\n",
    "\n",
    "print(\"num_features\")\n",
    "print(num_features)\n",
    "\n",
    "#4. Fully Connected Layer 1\n",
    "layer_fc1 = new_fc_layer(input=layer_flat,\n",
    "                         num_inputs=num_features,\n",
    "                         num_outputs=fc_size,\n",
    "                         use_relu=True)\n",
    "print(\"layer_fc1\")\n",
    "print(layer_fc1)\n",
    "\n",
    "#5. Fully Connected Layer 2\n",
    "layer_fc2 = new_fc_layer(input=layer_fc1,\n",
    "                         num_inputs=fc_size,\n",
    "                         num_outputs=num_classes,\n",
    "                         use_relu=False)\n",
    "print(\"layer_fc2\")\n",
    "print(layer_fc2)\n",
    "\n",
    "#Predicted Class\n",
    "y_pred = tf.nn.softmax(layer_fc2)\n",
    "y_pred_cls = tf.argmax(y_pred, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A.3 Cost-function to be optimized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_entropy = tf.nn.softmax_cross_entropy_with_logits(logits=layer_fc2, labels=y_true)\n",
    "cost = tf.reduce_mean(cross_entropy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A.4 Optimization method and Performance measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.train.AdamOptimizer(learning_rate=1e-4).minimize(cost)\n",
    "\n",
    "correct_prediction = tf.equal(y_pred_cls, y_true_cls)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2 Tensorflow Run Part B TensorFlow Session\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = tf.Session()\n",
    "#sess = tf.Session()\n",
    "#Once the TensorFlow graph has been created, we have to create a \n",
    "#TensorFlow session which is used to execute the graph.\n",
    "\n",
    "session.run(tf.global_variables_initializer())\n",
    "#The variables for weights and biases must be initialized before we start optimizing them.\n",
    "\n",
    "batch_size = 80\n",
    "#Stochastic Gradient Descent which only uses a small batch of images in each iteration of the optimizer.\n",
    "\n",
    "\n",
    "feed_dict_test = {x: data.test.images,\n",
    "                  y_true: data.test.labels}\n",
    "                  #y_true_cls: data.test.cls}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Optimize Function\n",
    "\n",
    "def optimize(num_iterations):\n",
    "    for i in range(num_iterations):\n",
    "        # Get a batch of training examples.\n",
    "        # x_batch now holds a batch of images and\n",
    "        # y_true_batch are the true labels for those images.\n",
    "        x_batch, y_true_batch = data.train.next_batch(batch_size=batch_size)\n",
    "        \n",
    "        # Put the batch into a dict with the proper names\n",
    "        # for placeholder variables in the TensorFlow graph.\n",
    "        # Note that the placeholder for y_true_cls is not set\n",
    "        # because it is not used during training.\n",
    "        feed_dict_train = {x: x_batch, y_true: y_true_batch}\n",
    "\n",
    "        # Run the optimizer using this batch of training data.\n",
    "        # TensorFlow assigns the variables in feed_dict_train\n",
    "        # to the placeholder variables and then runs the optimizer.\n",
    "        session.run(optimizer, feed_dict=feed_dict_train)\n",
    "        \n",
    "def print_accuracy():\n",
    "    # Use TensorFlow to compute the accuracy.\n",
    "    acc = session.run(accuracy, feed_dict=feed_dict_test)\n",
    "    \n",
    "    # Print the accuracy.\n",
    "    print(\"Accuracy on test-set: {0:.1%}\".format(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print_accuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimize(num_iterations=1)\n",
    "print_accuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimize(num_iterations=1000)\n",
    "print_accuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimize(num_iterations=10000)\n",
    "print_accuracy()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
